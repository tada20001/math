{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분산은 확률분포함수의 중앙에 확률이 얼마나 모여있는가를 표현한 값이다. \n",
    "\n",
    "##### 기대값이 확률변수에서 어떤 값이 나올지를 예측한 것이라면 분산은 그 예측의 정확도 혹은 신뢰성을 표현한 것이라고 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확률분포의 분산\n",
    "\n",
    "확률밀도함수  𝑝(𝑥) 의 수식을 알고 있다면 이론적인 분산을 구할 수 있다. 분산을 구하는 연산은 영어 Variance의 앞글자를 따서  Var[⋅] 로 표기하고 이 연산으로 계산된 분산값은  𝜎2 으로 표기한다.\n",
    "\n",
    "$$\\sigma^2 = \\text{Var}[X] = \\text{E}[(X - \\mu)^2]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이산확률변수의 분산은 평균으로부터 표본 데이터까지 거리의 제곱을 확률질량함수  𝑝(𝑥) 로 가중하여 더한 값이다.\n",
    "\n",
    "$$\\sigma^2 = \\sum_{x_i \\in \\Omega} (x_i - \\mu)^2 p(x_i)$$\n",
    "\n",
    "연속확률변수의 분산은 평균으로부터 표본 데이터까지 거리의 제곱을 확률밀도함수  𝑝(𝑥) 로 가중하여 적분한 값이다.\n",
    "\n",
    "$$\\sigma^2 = \\int_{-\\infty}^{\\infty} (x - \\mu)^2 p(x)dx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분산의 성질\n",
    "\n",
    "분산은 다음과 같은 성질을 만족한다.\n",
    "\n",
    "+ 분산은 항상 0 또는 양수이다.\n",
    "\n",
    "$$\\text{Var}[X] \\geq 0$$\n",
    "\n",
    "+ 확률변수가 아닌 상수 값  𝑐 에 대해 다음 식이 성립한다.\n",
    "$$\\text{Var}[c] = 0$$\n",
    "\n",
    "$$\\text{Var}[cX] = c^2 \\text{Var}[X]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또한 기댓값의 성질을 이용하여 다음 성질을 증명할 수 있다.\n",
    "\n",
    "$$\\text{Var}[X] = \\text{E}[X^2] - (\\text{E}[X])^2  = \\text{E}[X^2] - \\mu^2$$\n",
    "\n",
    "또는\n",
    "\n",
    "$$\\text{E}[X^2] = \\mu^2 + \\text{Var}[X]$$\n",
    "\n",
    "(증명)\n",
    "\\begin{aligned}\n",
    "\\text{Var}[X] \n",
    "&= \\text{E}[(X - \\mu)^2] \\\\\n",
    "&= \\text{E}[X^2 - 2\\mu X + \\mu^2] \\\\\n",
    "&= \\text{E}[X^2] - 2\\mu\\text{E}[X] + \\mu^2 \\\\\n",
    "&= \\text{E}[X^2] - 2\\mu^2 + \\mu^2 \\\\\n",
    "&= \\text{E}[X^2] - \\mu^2\\\\\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 두 확률변수의 합의 분산\n",
    "\n",
    "두 확률변수  𝑋 ,  𝑌 의 합의 분산은 각 확률변수의 분산의 합과 다음과 같은 관계가 있다.\n",
    "\n",
    "$$\\text{Var}\\left[ X + Y \\right] =\n",
    "\\text{Var}\\left[ X \\right] + \\text{Var}\\left[ Y \\right]+ 2\\text{E}\\left[ (X-\\mu_X)(Y-\\mu_Y) \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막 항은 양수도 될 수 있고 음수도 될 수 있다.\n",
    "\n",
    "이 식의 증명은 다음과 같다. \n",
    "\n",
    "우선 확률변수  𝑋+𝑌 의 기댓값은 기대값의 성질로부터 각 확률변수의 기대값의 합과 같다.\n",
    "\n",
    "$$\\text{E}[X + Y] = \\mu_X + \\mu_Y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분산의 정의와 기댓값의 성질로부터 다음이 성립한다.\n",
    "\n",
    "\\begin{aligned}\n",
    "\\text{Var}\\left[ X + Y \\right] \n",
    "&= \\text{E}\\left[ (X + Y - (\\mu_X + \\mu_Y))^2 \\right] \\\\\n",
    "&= \\text{E}\\left[ ((X -\\mu_X) + (Y - \\mu_Y))^2 \\right] \\\\\n",
    "&= \\text{E}\\left[ (X -\\mu_X)^2 + (Y - \\mu_Y)^2 + 2(X-\\mu_X)(Y-\\mu_Y) \\right] \\\\\n",
    "&= \\text{E}\\left[ (X -\\mu_X)^2 \\right] + \\text{E}\\left[ (Y - \\mu_Y)^2 \\right] + 2\\text{E}\\left[ (X-\\mu_X)(Y-\\mu_Y) \\right] \n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확률변수의 독립\n",
    "\n",
    "두 확률변수가 서로 독립(independent)이라는 것은 두 확률변수가 가질 수 있는 모든 사건의 조합에 대해 결합사건의 확률이 각 사건의 확률의 곱과 같다는 뜻이다. 쉽게 생각하면 두 확률변수가 서로에게 영향을 미치지 않는다라는 의미로 생각해도 된다. 예를 들어 주사위를 두 번 던져 각각 나오는 값을 나타내는 확률변수  𝑋1 과  𝑋2 는 서로 독립이다.\n",
    "\n",
    "독립의 반대, 즉 두 확률변수에서 하나의 확률변수의 값이 특정한 값이면 다른 확률변수의 확률분포가 영향을 받아 변하게 되면 종속(dependent)이라고 한다. 쉽게 생각하면 두 확률변수가 서로에게 영향을 미치는 경우이다. 예를 들어 주사위를 두 번 던져 나오는 값의 합은 각각의 주사위에서 나온 값에 종속적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice 1\n",
    "\n",
    "1. 서로 독립이라고 생각되는 두 확률변수의 예를 들어라.\n",
    "2. 서로 종속이라고 생각되는 두 확률변수의 예를 들어라."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 확률변수  𝑋 ,  𝑌 가 서로 독립이면 다음 식이 성립한다.\n",
    "\n",
    "$$\\text{E}\\left[ (X-\\mu_X)(Y-\\mu_Y) \\right] = 0$$\n",
    "\n",
    "왜 이 등식이 성립하는가는 추후 설명하기로 한다. 이 등식을 이용하면 서로 독립인 두 확률변수의 합의 분산은 각 확률변수의 분산의 합과 같다는 것을 보일 수 있다.\n",
    "\n",
    "$$\\text{Var}\\left[ X + Y \\right] =  \\text{Var}\\left[ X \\right] + \\text{Var}\\left[ Y \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice 2\n",
    "\n",
    "1. 넘파이를 사용하여 숫자 100개를 무작위로 생성하여 표본집합을 구한다. 이 표본집합을 확률변수  𝑋1 의 표본이라고 하자.\n",
    "2. 같은 방식으로 숫자 100개를 생성하며 확률변수  𝑋2 의 표본집합을 구한다.\n",
    "3. 두 확률변수의 표본 쌍의 값을 더하여 확률변수  𝑋1+𝑋2 의 표본집합을 구한다.\n",
    "4. 𝑋1+𝑋2 의 표본분산과  𝑋1 ,  𝑋2 의 표본분산값의 합을 각각 계산하여 두 값이 비슷함을 보여라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X1 = np.random.rand(100)\n",
    "X2 = np.random.rand(100)\n",
    "Y = X1 + X2\n",
    "\n",
    "var_1 = np.var(X1, ddof=1)\n",
    "var_2 = np.var(X2, ddof=1)\n",
    "var_y = np.var(Y, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1711596381877012"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_1 + var_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15760423406903334"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 표본평균의 분산\n",
    "\n",
    "확률변수  𝑋 의 표본평균  𝑋¯ 도 확률변수이고 그 기댓값  E[𝑋¯] 은 원래 확률변수  𝑋 의 기댓값  E[𝑋] 과 같다는 것을 증명한 적이 있다.\n",
    "\n",
    "$$\\text{E}[\\bar{X}] = \\text{E}[{X}] $$\n",
    "\n",
    "표본평균  𝑋¯ 의 분산  Var[𝑋¯] 은 원래 확률변수  𝑋 의 분산  Var[𝑋] 과 다음 관계를 가진다.\n",
    "\n",
    "$$\\text{Var}[\\bar{X}] = \\dfrac{1}{N} \\text{Var}[{X}]$$\n",
    "\n",
    " \n",
    "따라서 표본평균을 계산한 표본 개수가 커지면 표본평균의 값의 변동은 작아진다. 표본의 수가 무한대가 되면 표본평균의 값은 항상 일정한 값이 나온다. 즉 확률적인 값이 아니라 결정론적인 값이 된다.\n",
    "\n",
    "증명은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\text{Var}[\\bar{X}] \n",
    "&= \\text{E} \\left[ \\left( \\bar{X} -  \\text{E} \\left[ \\bar{X} \\right] \\right)^2 \\right] \\\\\n",
    "&= \\text{E} \\left[ \\left( \\bar{X} -  \\mu \\right)^2 \\right] \\\\\n",
    "&= \\text{E} \\left[ \\left( \\dfrac{1}{N} \\sum_{i=1}^N X_i - \\mu \\right)^2 \\right] \\\\\n",
    "&= \\text{E} \\left[ \\left( \\dfrac{1}{N} \\sum_{i=1}^N X_i - \\dfrac{1}{N}N\\mu \\right)^2 \\right] \\\\\n",
    "&= \\text{E} \\left[ \\left( \\dfrac{1}{N} \\left( \\sum_{i=1}^N X_i - N\\mu \\right) \\right)^2 \\right] \\\\\n",
    "&= \\text{E} \\left[ \\left( \\dfrac{1}{N} \\sum_{i=1}^N (X_i - \\mu) \\right)^2 \\right] \\\\\n",
    "&= \\text{E} \\left[ \\dfrac{1}{N^2} \\sum_{i=1}^N \\sum_{j=1}^N (X_i - \\mu) (X_j - \\mu)  \\right] \\\\\n",
    "&= \\dfrac{1}{N^2} \\sum_{i=1}^N \\sum_{j=1}^N \\text{E} \\left[  (X_i - \\mu) (X_j - \\mu)  \\right] \\\\\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "𝑖 번째 표본값은 𝑗번째(𝑖≠𝑗) 표본값에 영향을 미치지 않으므로 𝑋𝑖와 𝑋𝑗 (𝑖≠𝑗)는 독립이다. 따라서\n",
    "\n",
    "$$\\text{E}\\left[ (X_i-\\mu)(X_j-\\mu) \\right] = 0 \\;\\; (i \\neq j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라는 사실을 이용하면  𝑖=𝑗 인 항, 즉 제곱항만 남는다.\n",
    "\n",
    "\\begin{aligned}\n",
    "\\text{Var}[\\bar{X}]\n",
    "&= \\dfrac{1}{N^2} \\sum_{i=1}^N \\text{E} \\left[ (X_i - \\mu)^2 \\right] \\\\\n",
    "&= \\dfrac{1}{N^2} \\sum_{i=1}^N \\text{E} \\left[ (X - \\mu)^2 \\right] \\\\\n",
    "&= \\dfrac{1}{N^2} N \\text{E} \\left[ (X - \\mu)^2 \\right] \\\\\n",
    "&= \\dfrac{1}{N} \\text{E} \\left[ (X - \\mu)^2 \\right] \\\\\n",
    "&= \\dfrac{1}{N} \\text{Var}[X] \\\\\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 식이 의미하는 바는 다음과 같다.\n",
    "\n",
    "+ 데이터를 생성하는 확률변수  𝑋 의 기댓값을 구하려면 확률밀도함수  𝑝(𝑥) 의 수식을 알아야 한다.\n",
    "+ 그런데 우리는 데이터를 생성하는 확률변수  𝑋 의 확률밀도함수  𝑝(𝑥) 의 수식을 정확히 알지 못한다.\n",
    "+ 하지만 표본평균이라는 새로운 확률변수  𝑋¯ 의 기댓값  E[𝑋¯] 은 원래 확률변수  𝑋 의 기댓값  E[𝑋] 과 같으므로 표본평균  𝑥¯ 는 원래 확률변수  𝑋 의 기댓값  E[𝑋] 과 비슷한 값이 나올 것이다. 하지만 정확한 값은 아니다.\n",
    "+ 만약 표본 개수  𝑁 이 크면 표본평균  𝑥¯ 의 분산이 아주 작아지므로 표본평균의 값  𝑥¯ 은 항상 표본평균의 기댓값  E[𝑋¯]=E[𝑋]  근처의 거의 일정한 값이 나올 것이다.\n",
    "+ 따라서 표본 개수  𝑁 가 크면 표본평균  𝑥¯ 은 원래 확률변수  𝑋 의 기댓값  E[𝑋] 의 근사값이라고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice 3\n",
    "\n",
    "(1) 넘파이를 사용하여 숫자 100개를 무작위로 생성하여 표본집합을 구한다. 이 표본집합을 확률변수  𝑋1 의 표본이라고 하자.  𝑋1 의 표본분산을 계산한다.\n",
    "\n",
    "(2) 같은 작업을 50번 반복하여 확률변수  𝑋2,𝑋3,…,𝑋50 의 표본집합을 구한다.\n",
    "\n",
    "(3) 확률변수  𝑋𝑖 의 표본집합의 표본평균  𝑥¯𝑖 를 각각 계산한다. 이 값들은 표본평균 확률변수  𝑋¯ 의 표본집합이다.\n",
    "\n",
    "(4) 확률변수  𝑋¯ 의 표본분산값을 계산하고  𝑋1 의 표본분산과의 비율을 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.ones(100 * 50).reshape(50, 100)\n",
    "mean = np.zeros(50)\n",
    "\n",
    "for i in range(50):\n",
    "    X[i] = np.random.rand(100)\n",
    "    mean[i] = np.mean(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99052806, 0.51209105, 0.70985069, ..., 0.54167341, 0.60195626,\n",
       "        0.57469431],\n",
       "       [0.56575958, 0.0114397 , 0.5560268 , ..., 0.30991613, 0.60734189,\n",
       "        0.45136138],\n",
       "       [0.34223944, 0.7846746 , 0.57702015, ..., 0.33949636, 0.75266393,\n",
       "        0.04724738],\n",
       "       ...,\n",
       "       [0.8744352 , 0.80539741, 0.34545637, ..., 0.56697652, 0.95622174,\n",
       "        0.75195915],\n",
       "       [0.26268861, 0.58691095, 0.97240339, ..., 0.38306882, 0.75387133,\n",
       "        0.15920778],\n",
       "       [0.07046636, 0.36513454, 0.11271284, ..., 0.25185839, 0.25826845,\n",
       "        0.6292108 ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2) 같은 작업을 50번 반복하여 확률변수 𝑋2,𝑋3,…,𝑋50 의 표본집합을 구한다\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48616862, 0.51241204, 0.5250775 , 0.42699409, 0.47390996,\n",
       "       0.47787602, 0.49815545, 0.49972071, 0.5415467 , 0.50017338,\n",
       "       0.49840375, 0.47265617, 0.49199704, 0.506187  , 0.5161207 ,\n",
       "       0.47754212, 0.51362054, 0.49027599, 0.51474773, 0.530089  ,\n",
       "       0.48436679, 0.53953434, 0.53803292, 0.4843715 , 0.51395117,\n",
       "       0.53704541, 0.54613304, 0.49305527, 0.52333061, 0.54008887,\n",
       "       0.51323851, 0.5235917 , 0.49451756, 0.47012439, 0.4816786 ,\n",
       "       0.51802559, 0.51335156, 0.53731771, 0.50048346, 0.45751485,\n",
       "       0.47489951, 0.4555838 , 0.52196527, 0.49390135, 0.51106843,\n",
       "       0.49669532, 0.46658005, 0.46830488, 0.49351264, 0.46353168])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(3) 확률변수  𝑋𝑖 의 표본집합의 표본평균  𝑥¯𝑖 를 각각 계산한다. \n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124.03129266474009"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (4) 확률변수  𝑋¯ 의 표본분산값을 계산하고  𝑋1 의 표본분산과의 비율\n",
    "X[0].var() / mean.var() \n",
    " \n",
    "## 표본평균 확률변수의 분산은 거의 0에 가까우나 X1의 표본집합 확률변수는 분산이 큼. 이 경우, 124배 차이가 남"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 표본분산의 기대값\n",
    "\n",
    "앞에서 표본평균의 기대값을 구하면 이론적인 평균 즉, 기대값과 같아진다는 것을 증명했다.\n",
    "\n",
    "그런데 표본분산  𝑆2 의 기대값을 구하면 이론적인 분산  𝜎2 과 같아지는 것이 아니라 이론적인 분산값의  𝑁−1𝑁 배가 된다. 즉 표본분산값이 이론적인 분산값보다 더 작아진다.\n",
    "\n",
    "$$\\text{E}[S^2] = \\dfrac{N-1}{N}\\sigma^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "표본분산의 기대값이 정확하게  𝜎2 이 되려면 평균과의 거리의 제곱의 평균을 구할 때 분모가  𝑁 이 아니라  𝑁−1 으로 써야 한다.\n",
    "\n",
    "\\begin{aligned}\n",
    "\\sigma^2 \n",
    "&= \\dfrac{N}{N-1} \\text{E}[S^2] \\\\\n",
    "&= \\dfrac{N}{N-1} \\text{E} \\left[ \\dfrac{1}{N} \\sum (X_i-\\bar{X})^2 \\right] \\\\\n",
    "&= \\text{E} \\left[ \\dfrac{1}{N-1} \\sum (X_i-\\bar{X})^2 \\right]\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 기댓값이 정확한 분산값과 일치하는 비편향 표본분산은 다음처럼 정의한다.\n",
    "\n",
    "$$S^2_{\\text{unbiased}} \\equiv \\dfrac{1}{N-1} \\sum (X_i-\\bar{X})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 표본분산이 실제 분산보다 작아지는 이유는 다음과 같다.\n",
    "\n",
    "1. 표본분산을 계산할 때 사용하는 표본평균의 값이 데이터가 많이 몰려있는 쪽으로 편향되게 나온다.\n",
    "2. 이렇게 데이터가 몰려있는 위치에 있는 표본평균을 기준으로 각 데이터까지의 거리를 계산하면 원래의 기댓값으로부터의 거리보다 작게 나올 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 데이터로 예를 들어 살펴보자. 기대값  𝜇=0 , 분산이  𝜎2=1 인 정규분포로부터 5개의 표본을 뽑는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(15)\n",
    "N = 7\n",
    "data = np.sort(np.random.normal(size=(N)))[::-1]  # 내림차순으로 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33928471,  0.23556889, -0.15590853, -0.31232848, -0.50178967,\n",
       "       -1.09586204, -1.76360526])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 표본의 표본평균은 약 -0.46이다. 우연히 음수인 표본이 많이 나오는 바람에 원래의 기댓값 0에서 음수쪽으로 떨어진 값이 나왔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.46494862738581794"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.mean(data)\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터와 표본평균의 위치를 그림으로 그리면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "path = \"/Library/Fonts/NanumGothic.otf\"\n",
    "font_name = fm.FontProperties(fname=path, size=20).get_name()\n",
    "\n",
    "plt.rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 2))\n",
    "sns.rugplot(data, height=0.5, linewidth=4)\n",
    "x = np.linspace(-3, 3, 100)\n",
    "plt.axvline(x=0, ls=\":\", c=\"r\", linewidth=2, label=\"실제 기대값\")\n",
    "plt.axvline(x=mean, ls=\"--\", c=\"b\", linewidth=2, label=\"표본평균\")\n",
    "plt.legend()\n",
    "plt.xlim(-2, 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33928471,  0.23556889, -0.15590853, -0.31232848, -0.50178967,\n",
       "       -1.09586204, -1.76360526])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "표본표준편차는 표본평균으로부터 각 데이터가 떨어진 거리(의 제곱)의 평균이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.80423333,  0.70051752,  0.30904009,  0.15262015, -0.03684105,\n",
       "       -0.63091342, -1.29865663])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_from_sample_mean = data - mean\n",
    "distance_from_sample_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 거리들은 진짜 평균(기댓값)으로부터 각 데이터가 떨어진 거리보다 평균적으로 작게 나온다. 그 이유는 우리가 생각한 기대값인 표본평균이 우연히 왼쪽으로 몰려나온 데이터들 중간에 있기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4774618257836171"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_variance = (distance_from_sample_mean ** 2).mean()\n",
    "sample_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 표본분산값은 정확한 분산값보다 작은 값이다.  𝑁−1 로 나누어 편향 보정한 값은 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5570387967475533"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_variance * N / (N - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주의할 점은 표본분산의 기댓값이 원래의 분산값보다 작은 값이 나오는 경향이 있다는 것이지 항상 원래의 분산값보다 작게 나온다는 뜻은 아니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비대칭도와 첨도\n",
    "\n",
    "비대칭도(skew)는 3차 모멘트 값에서 계산하고 확률밀도함수의 비대칭 정도를 가리킨다. 비대칭도가 0이면 확률분포가 대칭이다.\n",
    "\n",
    "$$\\operatorname{E}\\left[\\left(\\frac{X-\\mu}{\\sigma}\\right)^3 \\right] = \\frac{\\mu_3}{\\sigma^3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첨도(kurtosis)는 4차 모멘트 값에서 계산하며 확률이 정규분포와 대비하여 중심에 모여있는지 바깥으로 퍼져있는지를 나타낸다.\n",
    "\n",
    "$$\\operatorname{E}\\left[\\left(\\frac{X-\\mu}{\\sigma}\\right)^4 \\right] = \\frac{\\mu_4}{\\sigma^4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모멘트\n",
    "\n",
    "앞서 구한 기대값이나 분산은 확률분포의 모멘트(moment) 중 하나다.\n",
    "\n",
    "$$\\mu_n = \\operatorname{E}[(X-\\mu)^n] = \\int (x - \\mu)^n p(x)dx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모멘트는 확률분포에서 계산한 특징값이다. 만약 두 확률분포  𝑋,𝑌 가 있고 1차부터 무한대 차수에 이르기까지 두 확률분포의 모든 모멘트값이 서로 같다면 두 확률분포는 같은 확률분포다.\n",
    "\n",
    "\\begin{aligned}\n",
    "\\text{E}[X] &= \\text{E}[Y] \\\\\n",
    "\\text{E}[(X-\\mu_X)^2] &= \\text{E}[(Y-\\mu_Y)^2] \\\\\n",
    "\\text{E}[(X-\\mu_X)^3] &= \\text{E}[(Y-\\mu_Y)^3] \\\\\n",
    "\\text{E}[(X-\\mu_X)^4] &= \\text{E}[(Y-\\mu_Y)^4] \\\\\n",
    "\\text{E}[(X-\\mu_X)^5] &= \\text{E}[(Y-\\mu_Y)^5] \\\\\n",
    " & \\vdots & \\\\\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이면\n",
    "\n",
    "$$X \\stackrel d= Y$$\n",
    "\n",
    "이다.  =𝑑  는 두 확률변수가 같은 분포(distribution)에서 나왔다는 것을 표시하는 기호다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
